{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTJuaUTzTqJf"
      },
      "outputs": [],
      "source": [
        "#Data analysis\n",
        "# Data Analysis. Data Analysis is the process of systematically applying statistical and/or logical techniques to describe and illustrate, condense and recap, and evaluate data.\n",
        "# Data aes of Data are as follows\n",
        "# Tabular Data > csu > xls > url > jsort > aps.\n",
        "# Tabulation is a systematic and logical representation of numeric data in rows and columns to facilitate comparison and statistical analysis. It facilitates comparison by bringing related information close to each other and helps in statistical analysis and interpretation.\n",
        "# Categorical variables represent types of data which may be divided into groups. Examples of categorical variables are race, sex, age group, and educational level.\n",
        "# Continuous data is a type of numerical data that refers to the unspecified number of possible measurements between two realistic points. These numbers are not always clean and tidy like those in discrete data, as they're usually collected from precise measurements.\n",
        "\n",
        "#Example :\n",
        "# One example of a data analysis report is the executive report on a company's digital marketing efforts. It presents evidence backed by data on how different channels create opportunities for a business to serve its customers better and, in return, achieve sustainable growth.\n",
        "\n",
        "#Domain Knowledge\n",
        "# Domain knowledge gives data analysts the necessary context for turning data into actionable insights. It allows them to correctly interpret data, identify meaningful patterns, and provide recommendations addressing real-world business issues.\n",
        "\n",
        "#Example:\n",
        "# When building a model to predict credit defaults, a false negative (predicting a potential defaulter to be in good credit) is costlier than a false positive (predicting a non-defaulter to be a defaulter).\n",
        "\n",
        "# Grouped data are data formed by aggregating individual observations of a variable into groups, so that a frequency distribution of these groups serves as a convenient means of summarizing or analyzing the data.\n",
        "# A common task seen in data analysis is to group the data into different categories and then perform calculations on the resultant groups of data.\n",
        "# Analysis is the process of cleaning, changing, and processing raw data and extracting actionable, relevant information that helps businesses make informed decisions.\n",
        "# Primary data are those that are collected for the first time. Secondary data refer to those data that have already been collected by some other person. These are original because these are collected by the investigator for the first time.\n",
        "\n",
        "#Example:\n",
        "# Suppose we have a data ranges from 0 to 50 like 2, 17, 0, 1, 8, 19, 43, 2, 1, 32, and so on. In this case, we can group the data into classes such as 0-10, 10-20,…,40-50. This is a simple example of grouped data.\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Mean,Median,Mode\n",
        "# The mean (average) of a data set is found by adding all numbers in the data set and then dividing by the number of values in the set. The median is the middle value when a data set is ordered from least to greatest. The mode is the number that occurs most often in a data set.\n",
        "# Outliers are data points that deviate significantly from the rest of the data, while missing values are data points that are absent or incomplete. Here's how to handle outliers and missing values in your instrumentation data using some common methods and tools.\n",
        "\n",
        "#Example:\n",
        "#Mean = The mean formula to find the mean for an ungrouped set of data can be given as, mean = (sum of data values) / (number of data values).\n",
        "#Add the numbers together: 3 + 5 + 7 + 19 = 34\n",
        "#Divide the sum by the number of data points: 34 ÷ 4 = 8.5\n",
        "\n",
        "#Example:\n",
        "#Median = median value in a list with an even amount of numbers, one must determine the middle pair, add them, and divide by two. Again, arrange the numbers in order from lowest to highest.\n",
        "#in a data set of {3, 13, 2, 34, 11, 17, 27, 47}, the sorted order becomes {2, 3, 11, 13, 17, 27, 34, 47}. The median is the average of the two numbers in the middle {2, 3, 11, 13, 17, 26 34, 47}, which in this case is 15 or (13 + 17) ÷ 2 = 15.\n",
        "\n",
        "#Example:\n",
        "#Mode = mode is the value that is repeatedly occurring in a given set. We can also say that the value or number in a data set, which has a high frequency or appears more frequently, is called mode or modal value.\n",
        "#the mode of the set {3, 7, 8, 8, 9}, is 8. Therefore, for a finite number of observations, we can easily find the mode. A set of values may have one mode or more than one mode or no mode at all.\n",
        "\n",
        "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Analysing the data\n",
        "# Data Analysis is the process of systematically applying statistical and/or logical techniques to describe and illustrate, condense and recap, and evaluate data.\n",
        "\n",
        "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Cardinality\n",
        "# Cardinal utility analysis is the oldest theory of demand which provides an explanation of consumer's demand for a product and derives the law of demand which establishes an inverse relationship between price and quantity demanded of a product.\n",
        "# Data cardinality refers to the uniqueness of the values contained in a database column. If most of the values are distinct, then it is considered to have high cardinality. If the column contains mostly repeated values, that makes it a low cardinality column.\n",
        "\n",
        "#Example:\n",
        "#Data cardinality refers to the uniqueness of the values contained in a database column. If most of the values are distinct, then it is considered to have high cardinality. If the column contains mostly repeated values, that makes it a low cardinality column.\n",
        "#For example, if a person and passport are two identities, then one person can have exactly one passport and only one passport can be assigned to a person.\n",
        "\n",
        "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Pictorial representation\n",
        "# Among different type of data representations possible, the representation which consists of pictures i.e A pictorial representation of data is called pictograph.\n",
        "# The pictograph is a method to represent the data using images. Each image in the pictograph represents certain things. In other words, pictographs define the frequency of the data using images or symbols, which are relevant to the data.\n",
        "\n",
        "#Example:\n",
        "#Represent the money you spent on chocolate using a 25 cm long rectangular bar then the scale is 1 rupee is equal to one unit on the graph i.e. one rupee is represented by one centimeter.\n",
        "\n",
        "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Statistical representation\n",
        "# A statistical representation of data is a graphical way of representing data in statistics. It helps to understand the distribution of data and to identify any patterns. There are different types of graphs that can be used, depending on the type of data being represented.\n",
        "\n",
        "#Example:\n",
        "#If you want to know how many people are in each age category, then a table showing the number of people by age would be useful. In statistics, it is called a frequency distribution table (or just frequency).\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Univariant analysis\n",
        "# Univariate analysis is the simplest form of analyzing data. Uni means \"one\", so the data has only one variable (univariate). Univariate data requires to analyze each variable separately. Data is gathered for the purpose of answering a question, or more specifically, a research question.\n",
        "\n",
        "#Bivariate data\n",
        "#This type of data involves two different variables. The analysis of this type of data deals with causes and relationships and the analysis is done to find out the relationship among the two variables. Example of bivariate data can be temperature and ice cream sales in summer season.\n",
        "\n",
        "#Multivariate data\n",
        "#When the data involves three or more variables, it is categorized under multivariate.\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Relative Measure of Dispersion\n",
        "#The relative measures of dispersion are used to compare the distribution of two or more data sets. This measure compares values without units. Common relative dispersion methods include: Co-efficient of Range.\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Variance\n",
        "#In statistics, variance measures variability from the average or mean. It is calculated by taking the differences between each number in the data set and the mean, then squaring the differences to make them positive, and finally dividing the sum of the squares by the number of values in the data set.\n",
        "\n",
        "#Example1:\n",
        "#Variance Formula is σ2 = ∑ f (m − x̅)2 / n\n",
        "#The mean is given as (3 + 5 + 8 + 1) / 4 = 4.25. Then by using the definition of variance we get [(3 - 4.25)2 + (5 - 4.25)2 + (8 - 4.25)2 + (1 - 4.25)2] / 4 = 6.68. Thus, variance = 6.68.\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Kernel Entity Estimation\n",
        "# Kernel density estimation is a technique for estimation of probability density function that is a must-have enabling the user to better analyse the studied probability distribution than when using a traditional histogram.\n",
        "\n",
        "#Example:\n",
        "#Kernel density estimation is a non-parametric model also know as KDE, it's a technique that lets you create a smooth curve given a set of data. KDE basically centers a kernel function at each data point and smooths it to get a destiny estimate.\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Skewness\n",
        "# Skewness is a measurement of the distortion of symmetrical distribution or asymmetry in a data set. Skewness is demonstrated on a bell curve when data points are not distributed symmetrically to the left and right sides of the median on a bell curve.\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Inferential Statistics\n",
        "# Inferential statistics is the practice of using sampled data to draw conclusions or make predictions about a larger sample data sample or population.\n"
      ]
    }
  ]
}